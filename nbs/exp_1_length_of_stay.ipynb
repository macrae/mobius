{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floppy-series",
   "metadata": {},
   "source": [
    "## Siamese Neural Networks \n",
    "### for Supervised Clustering of High Dimensional Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suspended-camcorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.10\n",
      "/Users/michellemacrae/Documents/Sean/mobius/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "allied-spice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318438, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>Hospital_code</th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>City_Code_Hospital</th>\n",
       "      <th>Hospital_region_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Type</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>patientid</th>\n",
       "      <th>City_Code_Patient</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Visitors with Patient</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>Stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>Z</td>\n",
       "      <td>3</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>0-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5954.0</td>\n",
       "      <td>41-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>anesthesia</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>31-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>41-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>41-50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id  Hospital_code Hospital_type_code  City_Code_Hospital  \\\n",
       "0        1              8                  c                   3   \n",
       "1        2              2                  c                   5   \n",
       "2        3             10                  e                   1   \n",
       "3        4             26                  b                   2   \n",
       "4        5             26                  b                   2   \n",
       "\n",
       "  Hospital_region_code  Available Extra Rooms in Hospital    Department  \\\n",
       "0                    Z                                  3  radiotherapy   \n",
       "1                    Z                                  2  radiotherapy   \n",
       "2                    X                                  2    anesthesia   \n",
       "3                    Y                                  2  radiotherapy   \n",
       "4                    Y                                  2  radiotherapy   \n",
       "\n",
       "  Ward_Type Ward_Facility_Code  Bed Grade  patientid  City_Code_Patient  \\\n",
       "0         R                  F        2.0      31397                7.0   \n",
       "1         S                  F        2.0      31397                7.0   \n",
       "2         S                  E        2.0      31397                7.0   \n",
       "3         R                  D        2.0      31397                7.0   \n",
       "4         S                  D        2.0      31397                7.0   \n",
       "\n",
       "  Type of Admission Severity of Illness  Visitors with Patient    Age  \\\n",
       "0         Emergency             Extreme                      2  51-60   \n",
       "1            Trauma             Extreme                      2  51-60   \n",
       "2            Trauma             Extreme                      2  51-60   \n",
       "3            Trauma             Extreme                      2  51-60   \n",
       "4            Trauma             Extreme                      2  51-60   \n",
       "\n",
       "   Admission_Deposit   Stay  \n",
       "0             4911.0   0-10  \n",
       "1             5954.0  41-50  \n",
       "2             4745.0  31-40  \n",
       "3             7272.0  41-50  \n",
       "4             5558.0  41-50  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DOWNLOAD DATSET HERE: https://www.kaggle.com/nehaprabhavalkar/av-healthcare-analytics-ii\n",
    "los = pd.read_csv(\"data/train_data.csv\")\n",
    "\n",
    "print(los.shape)\n",
    "los.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ignored-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# sns.pairplot(los, hue='Stay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "normal-refund",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3184, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "los_sample, _ = train_test_split(\n",
    "    los,\n",
    "    test_size=0.99,\n",
    "    stratify=los[\"Stay\"])\n",
    "\n",
    "los_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-kentucky",
   "metadata": {},
   "source": [
    "## Tabular Learner\n",
    "\n",
    "Before we train the Tabular Siamese Learner we will train baseline Tabular Learner for species classification... (why do we do this, exactly? can we just instantiate a Tabular Siamese Learner without a baseline Tabular Learner ???)\n",
    "\n",
    "Ah yes, to init a new `TabularSiameseModel` we need to provide an `encoder` and `head` and the Tabular Learner will act as the `encoder` we init the `TabularSiameseModel` with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opposite-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# los_train, los_val = train_test_split(\n",
    "#     los,\n",
    "#     test_size=0.10,\n",
    "#     stratify=los[\"Stay\"])\n",
    "\n",
    "los_train, los_val = train_test_split(\n",
    "    los_sample,\n",
    "    test_size=0.10,\n",
    "    stratify=los_sample[\"Stay\"])\n",
    "\n",
    "los_train.shape, los_val.shape\n",
    "\n",
    "df = los_train.copy()\n",
    "\n",
    "exclude_vars = [\"case_id\", \"patientid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liberal-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import CategoryBlock\n",
    "                                \n",
    "# y_names = [\"species\"]\n",
    "y_names = [\"Stay\"]\n",
    "y_block = CategoryBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stock-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hospital_type_code': 5,\n",
       " 'Hospital_region_code': 3,\n",
       " 'Department': 4,\n",
       " 'Ward_Type': 4,\n",
       " 'Ward_Facility_Code': 4,\n",
       " 'Type of Admission': 3,\n",
       " 'Severity of Illness': 3,\n",
       " 'Age': 6,\n",
       " 'Stay': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mobius.utils import emb_sz_rule\n",
    "\n",
    "cat_names = [x for x in df.select_dtypes(exclude=['int', 'float']).columns if x != y_names]\n",
    "cat_names = [x for x in cat_names if x not in exclude_vars]\n",
    "\n",
    "# calc embedding sizes for each categorical feature\n",
    "emb_szs = {k: emb_sz_rule(len(df[k].unique())) for k in cat_names}\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "special-soldier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hospital_code',\n",
       " 'City_Code_Hospital',\n",
       " 'Available Extra Rooms in Hospital',\n",
       " 'Bed Grade',\n",
       " 'City_Code_Patient',\n",
       " 'Visitors with Patient',\n",
       " 'Admission_Deposit']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cont_names = [x for x in df.select_dtypes([np.number]).columns if x != y_names]\n",
    "cont_names = [x for x in cont_names if x not in exclude_vars]\n",
    "cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "every-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import (Categorify, CategoryBlock, FillMissing,\n",
    "                                Normalize, TabDataLoader, TabularPandas,\n",
    "                                tabular_config, tabular_learner)\n",
    "\n",
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "referenced-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import range_of\n",
    "from fastai.tabular.all import RandomSplitter\n",
    "\n",
    "# train/test split\n",
    "splits = RandomSplitter(valid_pct=0.10)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "threaded-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_pandas = TabularPandas(\n",
    "        df,\n",
    "        procs=procs,\n",
    "        cat_names=cat_names,\n",
    "        cont_names=cont_names,\n",
    "        y_names=y_names,\n",
    "        y_block=y_block,\n",
    "        splits=splits,\n",
    "        device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "centered-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = TabDataLoader(\n",
    "    tabular_pandas.train,\n",
    "    bs=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=4)\n",
    "\n",
    "val_dl = TabDataLoader(\n",
    "    tabular_pandas.valid,\n",
    "    bs=128,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unlikely-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n"
     ]
    }
   ],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)\n",
    "\n",
    "print(\"Sample batch:\")\n",
    "# dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "annoying-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import F1Score, Precision, Recall, accuracy\n",
    "\n",
    "# load the tabular_pandas data through the tabular_learner\n",
    "layers = [2048, 1024, 32, 2]\n",
    "\n",
    "# tabular learner configuration\n",
    "config = tabular_config(ps=[0.2, 0.1, 0.1, 0.0], embed_p=0.1)\n",
    "\n",
    "learn = tabular_learner(\n",
    "    dls,\n",
    "    layers=layers,\n",
    "    emb_szs=emb_szs,\n",
    "    config=config,\n",
    "    metrics=[accuracy,\n",
    "             Precision(average='macro'),\n",
    "             Recall(average='macro'),\n",
    "             F1Score(average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "limited-delta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.226802</td>\n",
       "      <td>2.430841</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.042744</td>\n",
       "      <td>0.120777</td>\n",
       "      <td>0.061860</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.092716</td>\n",
       "      <td>2.263538</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0.148267</td>\n",
       "      <td>0.183682</td>\n",
       "      <td>0.130910</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellemacrae/Documents/Sean/mobius/.venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michellemacrae/Documents/Sean/mobius/.venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(n_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "choice-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.export(\"tabular_learn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "clear-enclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before temperature - NLL: 2.264, ECE: 0.104\n",
      "Optimal temperature: 0.932\n",
      "After temperature - NLL: 2.261, ECE: 0.128\n"
     ]
    }
   ],
   "source": [
    "from mobius.calibration import ModelWithTemperature\n",
    "\n",
    "scaled_model = ModelWithTemperature(learn.model)\n",
    "scaled_model.set_temperature(val_dl)\n",
    "learn.model = scaled_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "increased-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellemacrae/Documents/Sean/mobius/.venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# true species labels\n",
    "y_true=learn.dls.valid.items[\"Stay\"]\n",
    "\n",
    "# model scores and species predictions\n",
    "y_scores, *_ = learn.get_preds(dl=val_dl)\n",
    "preds = np.argmax(y_scores, 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "engaging-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 species labels and predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 4),\n",
       " (7, 4),\n",
       " (1, 4),\n",
       " (3, 4),\n",
       " (3, 4),\n",
       " (1, 4),\n",
       " (7, 4),\n",
       " (3, 4),\n",
       " (1, 2),\n",
       " (3, 4)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First 20 species labels and predictions\")\n",
    "list(zip(y_true, preds))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "congressional-buffalo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2097902097902098"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_true == preds).sum() / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-danish",
   "metadata": {},
   "source": [
    "## Siamese Net\n",
    "\n",
    "To init a new `TabularSiameseDataset` object, we only need a `tabular_pandas` object from the fast.ai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b490e4e7-22e4-46b6-8b56-c4990a004c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.datasets import write_jsonl\n",
    "\n",
    "# write SNN training data to `data/`\n",
    "write_jsonl(tabular_pandas.train.to.items[0].items, \"data/train_data.jsonl\")\n",
    "write_jsonl(tabular_pandas.valid.to.items[0].items, \"data/valid_data.jsonl\")\n",
    "\n",
    "# write SNN training labels to `data/`\n",
    "tabular_pandas.train.y.to_csv(\"data/train_labels.csv\", index=True)\n",
    "tabular_pandas.valid.y.to_csv(\"data/valid_labels.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "superb-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.datasets import TabularSiameseDataset\n",
    "\n",
    "train_ds = TabularSiameseDataset(\n",
    "    csv_file=\"data/train_labels.csv\", \n",
    "    jsonl_file=\"data/train_data.jsonl\",\n",
    "    tabular_learner=learn)\n",
    "    \n",
    "valid_ds = TabularSiameseDataset(\n",
    "    csv_file=\"data/valid_labels.csv\", \n",
    "    jsonl_file=\"data/valid_data.jsonl\",\n",
    "    tabular_learner=learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "royal-spanish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2579,\n",
       " ((tensor([1, 1, 3, 2, 6, 3, 2, 2, 3, 1, 1]),\n",
       "   tensor([ 0.5247,  0.4156,  3.2945,  1.6370, -1.3029,  2.6328, -1.7517])),\n",
       "  (tensor([2, 2, 2, 1, 4, 2, 1, 6, 3, 1, 1]),\n",
       "   tensor([ 0.8730, -0.8915,  0.7167,  0.4694, -0.0743,  0.4011, -0.7560])),\n",
       "  tensor(0.)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__len__(), train_ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfbe3319-2c8c-4c97-8f10-11964baeed6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286,\n",
       " ((tensor([1, 1, 3, 2, 6, 3, 2, 2, 3, 1, 1]),\n",
       "   tensor([ 0.5247,  0.4156,  3.2945,  1.6370, -1.3029,  2.6328, -1.7517])),\n",
       "  (tensor([1, 2, 3, 4, 3, 1, 1, 6, 5, 1, 1]),\n",
       "   tensor([ 0.0603,  0.7424, -1.0019, -0.6981,  0.1304,  1.5169, -0.2078])),\n",
       "  tensor(1.)))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds.__len__(), valid_ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stunning-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=16, device='cpu', num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-sustainability",
   "metadata": {},
   "source": [
    "Siamese net encoder is the body of the Tabular net we just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0a0628a-3bc4-4d9b-b01e-c3cd6f486487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.dataset.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aboriginal-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "encoder = copy.copy(learn)\n",
    "encoder.model.layers = learn.model.layers[:-1]\n",
    "encoder_model = encoder.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-peeing",
   "metadata": {},
   "source": [
    "We create a new head that doubles the input shape to the last layer of the trained Tabular net, since the loss function will now compare 2 penguins. The size of the output shape is set by...???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "magnetic-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.layers import LinBnDrop\n",
    "\n",
    "head = LinBnDrop(n_in=layers[-1]*2,\n",
    "    n_out=16,  # size of output space\n",
    "    bn=True,\n",
    "    act=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5319fe65-32c3-467e-b9dd-100c22098f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from fastai.callback.core import Callback\n",
    "\n",
    "\n",
    "# TODO: save every TSNE model as pkl - interactive 3-d w/ tooltip to show point information (id, features, etc.)\n",
    "class TSNECallback(Callback):\n",
    "    def after_validate(self):\n",
    "        plt.clf()\n",
    "        t = int(time.time())\n",
    "        train_encoded = list()\n",
    "        for i in range(len(siamese_learner.dls.valid.dataset.labels)):\n",
    "            p, _, _ = siamese_learner.dls.valid_ds.__getitem__(i)\n",
    "\n",
    "            # rehsape into mini-batch size 1\n",
    "            p = p[0].reshape(1, -1), p[1].reshape(1, -1)\n",
    "\n",
    "            # encode the household into output embedding space\n",
    "            p_encode = siamese_learner.model.encode(p)\n",
    "            train_encoded.append(p_encode)\n",
    "            \n",
    "        ids = self.dls.valid.get_idxs()\n",
    "        y_train_labels = self.dls.valid.dataset.labels[\"Stay\"]\n",
    "        train_encoded_df = pd.DataFrame(torch.stack(train_encoded).squeeze())\n",
    "\n",
    "        # write encoded space to csv\n",
    "        train_encoded_df.to_csv(f\"tsne_{t}_{self.epoch}.csv\")\n",
    "        \n",
    "        # limit the permutation of hyper-params of t-SNE\n",
    "        tsne = TSNE(n_components=2, metric=\"euclidean\", n_iter=500)\n",
    "        encoded_train_tsne = tsne.fit_transform(train_encoded_df.values)\n",
    "        np.save(f\"tsne_{t}_{self.epoch}.npy\", encoded_train_tsne)\n",
    "        \n",
    "        # TODO: add title...\n",
    "        sns.scatterplot(x=encoded_train_tsne[:,0],\n",
    "                        y=encoded_train_tsne[:,1],\n",
    "                        hue=y_train_labels, \n",
    "                        legend=False, \n",
    "                        palette=\"tab10\").figure.savefig(f\"snn_{t}_epoch_{self.epoch}.png\")\n",
    "        \n",
    "        \n",
    "# TODO: run knn on embedding space to show learned embedding is informative!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "expanded-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.models import TabularSiameseModel\n",
    "\n",
    "model = TabularSiameseModel(encoder_model, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "minute-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_basics import params\n",
    "from mobius.losses import ContrastiveLoss\n",
    "\n",
    "def siamese_splitter(model):\n",
    "    return [params(model.encoder), params(model.head)]\n",
    "\n",
    "def contrastive_loss_func(out, targ):\n",
    "    return ContrastiveLoss(margin=0.20)(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faced-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import Learner\n",
    "\n",
    "siamese_learner = Learner(dls,\n",
    "    model,\n",
    "    model_dir=\".\",\n",
    "    loss_func=contrastive_loss_func,\n",
    "    splitter=siamese_splitter,\n",
    "    cbs=[TSNECallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "995cd617-c4a8-45d9-aa23-6f71fa718f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_labels = siamese_learner.dls.valid.dataset.labels[\"Stay\"]\n",
    "# y_labels.to_csv(\"y_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94227847-7b94-4a77-af3a-14cb9415edff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TabularSiameseModel (Input shape: [\"['16 x 11', '16 x 7']\", \"['16 x 11', '16 x 7']\"])\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     16 x 5              \n",
       "Embedding                                 40         True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 3              \n",
       "Embedding                                 12         True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 4              \n",
       "Embedding                                 24         True      \n",
       "Embedding                                 24         True      \n",
       "Embedding                                 28         True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 3              \n",
       "Embedding                                 12         True      \n",
       "Embedding                                 12         True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 6              \n",
       "Embedding                                 66         True      \n",
       "Embedding                                 72         True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 3              \n",
       "Embedding                                 9          True      \n",
       "Embedding                                 9          True      \n",
       "Dropout                                                        \n",
       "BatchNorm1d                               14         True      \n",
       "BatchNorm1d                               102        True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048           \n",
       "Linear                                    104448     True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               4096       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024           \n",
       "Linear                                    2097152    True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               2048       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     16 x 32             \n",
       "Linear                                    32768      True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               64         True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 2              \n",
       "Linear                                    64         True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               8          True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 16             \n",
       "Linear                                    64         True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 2,241,136\n",
       "Total trainable params: 2,241,136\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x7ff74c6f90e0>\n",
       "Loss function: <function contrastive_loss_func at 0x7ff74d6a0710>\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback\n",
       "  - TSNECallback"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %debug\n",
    "siamese_learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sized-channel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>58.312202</td>\n",
       "      <td>32.501068</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31.172941</td>\n",
       "      <td>13.311623</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.305069</td>\n",
       "      <td>12.860377</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "siamese_learner.freeze()\n",
    "siamese_learner.fit(n_epoch=3, lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "executive-edwards",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.527887</td>\n",
       "      <td>11.070065</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11.559202</td>\n",
       "      <td>11.525859</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.512881</td>\n",
       "      <td>13.335747</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "siamese_learner.unfreeze()\n",
    "siamese_learner.fit(n_epoch=3, lr=10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebca100-602c-4761-b365-acaa81898aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: inspect margin, using log space grid search - .01, .1, .5, .75, 1., 10., 50. - hypothesis is that the margin is too low and space is collapsging\n",
    "# TODO: inspect the LR manually - smaller learning rates - maybe fix learning rate across grid search; maybe use lr_min / 2 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_learner.save(\"snn_margin_20\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobius (env)",
   "language": "python",
   "name": "mobius"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
