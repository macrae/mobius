{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "light-yacht",
   "metadata": {},
   "source": [
    "# Pharoah\n",
    "\n",
    "Building the structure of the sequence data and preparing it for the RNN is a whole entire job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "absolute-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "admission_table = {'Patient 1': {'PatientID':'A1234-B456', \n",
    "                          'Admission ID':[12,34,15], \n",
    "                          'AdmissionStartDate':['2019-01-03 9:34:55','2019-02-03 10:50:55','2019-04-03 12:34:55'],\n",
    "                          'AdmissionEndDate':['2019-01-07 8:45:43','2019-03-04 1:50:32','2019-04-03 5:38:18']},\n",
    "                   'Patient 2': {'PatientID':'B1234-C456', \n",
    "                          'Admission ID':[13,34], \n",
    "                          'AdmissionStartDate':['2018-01-03 9:34:55','2018-02-03 10:50:55'],\n",
    "                          'AdmissionEndDate':['2018-01-07 8:45:43','2018-03-04 1:50:32']}}\n",
    "\n",
    "admission_table = (pd.concat({k: pd.DataFrame(v) for k, v in admission_table.items()}).reset_index(level=1, drop=True))\n",
    "admission_table = admission_table.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "laden-radar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Admission ID</th>\n",
       "      <th>AdmissionStartDate</th>\n",
       "      <th>AdmissionEndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1234-B456</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-03 9:34:55</td>\n",
       "      <td>2019-01-07 8:45:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1234-B456</td>\n",
       "      <td>34</td>\n",
       "      <td>2019-02-03 10:50:55</td>\n",
       "      <td>2019-03-04 1:50:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1234-B456</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-04-03 12:34:55</td>\n",
       "      <td>2019-04-03 5:38:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1234-C456</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-01-03 9:34:55</td>\n",
       "      <td>2018-01-07 8:45:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1234-C456</td>\n",
       "      <td>34</td>\n",
       "      <td>2018-02-03 10:50:55</td>\n",
       "      <td>2018-03-04 1:50:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PatientID  Admission ID   AdmissionStartDate    AdmissionEndDate\n",
       "0  A1234-B456            12   2019-01-03 9:34:55  2019-01-07 8:45:43\n",
       "1  A1234-B456            34  2019-02-03 10:50:55  2019-03-04 1:50:32\n",
       "2  A1234-B456            15  2019-04-03 12:34:55  2019-04-03 5:38:18\n",
       "3  B1234-C456            13   2018-01-03 9:34:55  2018-01-07 8:45:43\n",
       "4  B1234-C456            34  2018-02-03 10:50:55  2018-03-04 1:50:32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "widespread-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patient_1 = {'PatientID':'A1234-B456', \n",
    "             'Admission ID':[12,34,15], \n",
    "             'PrimaryDiagnosisCode':[['E11.64','I25.812','I25.10'],\n",
    "                                     ['E11.64','I25.812','I25.10','780.96','784.0'],\n",
    "                                     ['E11.64','I25.812','I25.10','786.50','401.9','789.00']],\n",
    "             'CodingSystem':['ICD-9','ICD-9','ICD-9'],\n",
    "             'DiagnosisCodeDescription':[['Type 2 diabetes mellitus with hypoglycemia',\n",
    "                                          'Atherosclerosis of bypass graft of coronary artery of transplanted heart without angina pectoris',\n",
    "                                          'Atherosclerotic heart disease of native coronary artery without angina pectoris'],\n",
    "                                         ['Type 2 diabetes mellitus with hypoglycemia',\n",
    "                                          'Atherosclerosis of bypass graft of coronary artery of transplanted heart without angina pectoris',\n",
    "                                          'Atherosclerotic heart disease of native coronary artery without angina pectoris',\n",
    "                                          'Generalized Pain', 'Dizziness and giddiness'],\n",
    "                                         ['Type 2 diabetes mellitus with hypoglycemia',\n",
    "                                          'Atherosclerosis of bypass graft of coronary artery of transplanted heart without angina pectoris',\n",
    "                                          'Atherosclerotic heart disease of native coronary artery without angina pectoris',\n",
    "                                          'Chest pain, unspecified','Essential hypertension, unspecified',\n",
    "                                          'Abdominal pain, unspecified site']]}\n",
    "Patient_2 = {'PatientID':'B1234-C456', \n",
    "              'Admission ID':[13,34], \n",
    "              'PrimaryDiagnosisCode':[['M05.59','Z13.85','O99.35'],['M05.59','Z13.85','O99.35','D37.0']],\n",
    "              'CodingSystem':['ICD-9','ICD-9'],\n",
    "              'DiagnosisCodeDescription':[['Rheumatoid polyneuropathy with rheumatoid arthritis of multiple sites',\n",
    "                                           'Encounter for screening for nervous system disorders',\n",
    "                                           'Diseases of the nervous system complicating pregnancy, childbirth, and the puerperium'],\n",
    "                                          ['Rheumatoid polyneuropathy with rheumatoid arthritis of multiple sites',\n",
    "                                           'Encounter for screening for nervous system disorders',\n",
    "                                           'Diseases of the nervous system complicating pregnancy, childbirth, and the puerperium',\n",
    "                                           'Neoplasm of uncertain behavior of lip, oral cavity and pharynx']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "capable-wagner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Admission ID</th>\n",
       "      <th>CodingSystem</th>\n",
       "      <th>PrimaryDiagnosisCode</th>\n",
       "      <th>DiagnosisCodeDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1234-B456</td>\n",
       "      <td>12</td>\n",
       "      <td>ICD-9</td>\n",
       "      <td>E11.64</td>\n",
       "      <td>Type 2 diabetes mellitus with hypoglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1234-B456</td>\n",
       "      <td>12</td>\n",
       "      <td>ICD-9</td>\n",
       "      <td>I25.812</td>\n",
       "      <td>Atherosclerosis of bypass graft of coronary ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1234-B456</td>\n",
       "      <td>12</td>\n",
       "      <td>ICD-9</td>\n",
       "      <td>I25.10</td>\n",
       "      <td>Atherosclerotic heart disease of native corona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1234-B456</td>\n",
       "      <td>34</td>\n",
       "      <td>ICD-9</td>\n",
       "      <td>E11.64</td>\n",
       "      <td>Type 2 diabetes mellitus with hypoglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1234-B456</td>\n",
       "      <td>34</td>\n",
       "      <td>ICD-9</td>\n",
       "      <td>I25.812</td>\n",
       "      <td>Atherosclerosis of bypass graft of coronary ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PatientID  Admission ID CodingSystem PrimaryDiagnosisCode  \\\n",
       "0  A1234-B456            12        ICD-9               E11.64   \n",
       "1  A1234-B456            12        ICD-9              I25.812   \n",
       "2  A1234-B456            12        ICD-9               I25.10   \n",
       "3  A1234-B456            34        ICD-9               E11.64   \n",
       "4  A1234-B456            34        ICD-9              I25.812   \n",
       "\n",
       "                            DiagnosisCodeDescription  \n",
       "0         Type 2 diabetes mellitus with hypoglycemia  \n",
       "1  Atherosclerosis of bypass graft of coronary ar...  \n",
       "2  Atherosclerotic heart disease of native corona...  \n",
       "3         Type 2 diabetes mellitus with hypoglycemia  \n",
       "4  Atherosclerosis of bypass graft of coronary ar...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_ehr(Patient1,Patient2):\n",
    "    pt_diagnosis_table = [Patient1,Patient2]\n",
    "    pt_diagnosis_table = pd.concat([pd.DataFrame({k:v for k,v in d.items()}) for d in pt_diagnosis_table])\n",
    "    \n",
    "    pt_diagnosis_table = (pt_diagnosis_table.set_index(['PatientID', 'Admission ID','CodingSystem'])\n",
    "              .apply(lambda x: x.apply(pd.Series).stack())\n",
    "              .reset_index()\n",
    "              .drop('level_3', 1))\n",
    "    return pt_diagnosis_table\n",
    "\n",
    "def hash_key(df):\n",
    "    df['HashKey'] = df['PatientID'].\\\n",
    "    apply(lambda x: x.split('-')[0]) + '-' + df['Admission ID'].astype('str')\n",
    "    cols = [df.columns[-1]] + [col for col in df if col != df.columns[-1]]\n",
    "    return df[cols]\n",
    "\n",
    "diagnosis_table = process_ehr(Patient_1,Patient_2)\n",
    "diagnosis_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fundamental-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_table = hash_key(admission_table)\n",
    "diagnosis_table = hash_key(diagnosis_table)\n",
    "\n",
    "# Write files to data directory\n",
    "diagnosis_table.to_csv('data/Diagnosis_Table.csv',encoding='UTF-8',index=False)\n",
    "admission_table.to_csv('data/Admissions_Table.csv',encoding='UTF-8',index=False,date_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "instrumental-composite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating visit date mapping\n",
      "['A1234-12', 'A1234-B456', '12', '2019-01-03 9:34:55', '2019-01-07 8:45:43']\n",
      "['A1234-34', 'A1234-B456', '34', '2019-02-03 10:50:55', '2019-03-04 1:50:32']\n",
      "['A1234-15', 'A1234-B456', '15', '2019-04-03 12:34:55', '2019-04-03 5:38:18']\n",
      "['B1234-13', 'B1234-C456', '13', '2018-01-03 9:34:55', '2018-01-07 8:45:43']\n",
      "['B1234-34', 'B1234-C456', '34', '2018-02-03 10:50:55', '2018-03-04 1:50:32']\n"
     ]
    }
   ],
   "source": [
    "# %debug\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='white')\n",
    "\n",
    "print('Creating visit date mapping')\n",
    "patHashMap = dict(defaultdict(list))  # this creates a dictionary with a list of values for each patient:[number of visists]\n",
    "visitMap = dict(defaultdict()) # this creates a dictionary with a mapping of the patientID : visitdates\n",
    "\n",
    "data = open('data/Admissions_Table.csv','r')\n",
    "data.readline()[1:] # read every line except the file header\n",
    "\n",
    "for line in data:\n",
    "    feature = line.strip().split(',') # split line on , and isolate columns\n",
    "    print(feature)\n",
    "    visitDateID = datetime.strptime(feature[3],'%Y-%m-%d %H:%M:%S') \n",
    "    patHashMap.setdefault(feature[1], []).append(feature[0]) # create a mapping for each visit for a specific PatientID\n",
    "    visitMap.setdefault(feature[0], []).append(visitDateID) # create a mapping for each visit for a specific Admission Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aerial-portrait",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1234-B456': ['A1234-12', 'A1234-34', 'A1234-15'],\n",
       " 'B1234-C456': ['B1234-13', 'B1234-34']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Patient ID- visit mapping\n",
    "patHashMap\n",
    "\n",
    "# ```\n",
    "# {'A1234-B456': ['A1234-12', 'A1234-34', 'A1234-15'],\n",
    "#  'B1234-C456': ['B1234-13', 'B1234-34']}\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "falling-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1234-12': [datetime.datetime(2019, 1, 3, 9, 34, 55)],\n",
       " 'A1234-34': [datetime.datetime(2019, 2, 3, 10, 50, 55)],\n",
       " 'A1234-15': [datetime.datetime(2019, 4, 3, 12, 34, 55)],\n",
       " 'B1234-13': [datetime.datetime(2018, 1, 3, 9, 34, 55)],\n",
       " 'B1234-34': [datetime.datetime(2018, 2, 3, 10, 50, 55)]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Patient Admission ID- visit date mapping\n",
    "visitMap\n",
    "\n",
    "# ```\n",
    "# {'A1234-12': [datetime.datetime(2019, 1, 3, 0, 0)],\n",
    "#  'A1234-34': [datetime.datetime(2019, 2, 3, 0, 0)],\n",
    "#  'A1234-15': [datetime.datetime(2019, 4, 3, 0, 0)],\n",
    "#  'B1234-13': [datetime.datetime(2018, 1, 3, 0, 0)],\n",
    "#  'B1234-34': [datetime.datetime(2018, 2, 3, 0, 0)]}\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "reliable-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Diagnosis-Visit mapping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A1234-12': ['D_E11', 'D_I25', 'D_I25'],\n",
       " 'A1234-34': ['D_E11', 'D_I25', 'D_I25', 'D_780', 'D_784'],\n",
       " 'A1234-15': ['D_E11', 'D_I25', 'D_I25', 'D_786', 'D_401', 'D_789'],\n",
       " 'B1234-13': ['D_M05', 'D_Z13', 'D_O99'],\n",
       " 'B1234-34': ['D_M05', 'D_Z13', 'D_O99', 'D_D37']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Creating Diagnosis-Visit mapping')\n",
    "visitDxMap = dict(defaultdict(list))\n",
    "\n",
    "data = open('data/Diagnosis_Table.csv', 'r')\n",
    "data.readline()[1:]\n",
    "\n",
    "for line in data:\n",
    "    feature = line.strip().split(',')\n",
    "    visitDxMap.setdefault(feature[0], []).append('D_' + feature[4].split('.')[0]) # add a unique identifier before the\n",
    "    \n",
    "visitDxMap # Mapping of each Admission ID to each diagnosis code assigned during that visit\n",
    "\n",
    "# ```\n",
    "# {'A1234-12': ['D_E11', 'D_I25', 'D_I25'],\n",
    "#  'A1234-34': ['D_E11', 'D_I25', 'D_I25', 'D_780', 'D_784'],\n",
    "#  'A1234-15': ['D_E11', 'D_I25', 'D_I25', 'D_786', 'D_401', 'D_789'],\n",
    "#  'B1234-13': ['D_M05', 'D_Z13', 'D_O99'],\n",
    "#  'B1234-34': ['D_M05', 'D_Z13', 'D_O99', 'D_D37']}\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "radical-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting visit mapping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A1234-B456': [([datetime.datetime(2019, 1, 3, 9, 34, 55)],\n",
       "   ['D_E11', 'D_I25', 'D_I25']),\n",
       "  ([datetime.datetime(2019, 2, 3, 10, 50, 55)],\n",
       "   ['D_E11', 'D_I25', 'D_I25', 'D_780', 'D_784']),\n",
       "  ([datetime.datetime(2019, 4, 3, 12, 34, 55)],\n",
       "   ['D_E11', 'D_I25', 'D_I25', 'D_786', 'D_401', 'D_789'])],\n",
       " 'B1234-C456': [([datetime.datetime(2018, 1, 3, 9, 34, 55)],\n",
       "   ['D_M05', 'D_Z13', 'D_O99']),\n",
       "  ([datetime.datetime(2018, 2, 3, 10, 50, 55)],\n",
       "   ['D_M05', 'D_Z13', 'D_O99', 'D_D37'])]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sorting visit mapping\")\n",
    "patDxVisitOrderMap = {}\n",
    "for patid, visitDates in patHashMap.items():\n",
    "    sorted_list = ([(visitMap[visitDateID], visitDxMap[visitDateID]) for visitDateID in visitDates])\n",
    "    patDxVisitOrderMap[patid] = sorted_list \n",
    "  \n",
    "patDxVisitOrderMap\n",
    "\n",
    "# ```\n",
    "# {'A1234-B456': [([datetime.datetime(2019, 1, 3, 0, 0)],\n",
    "#    ['D_E11', 'D_I25', 'D_I25']),\n",
    "#   ([datetime.datetime(2019, 2, 3, 0, 0)],\n",
    "#    ['D_E11', 'D_I25', 'D_I25', 'D_780', 'D_784']),\n",
    "#   ([datetime.datetime(2019, 4, 3, 0, 0)],\n",
    "#    ['D_E11', 'D_I25', 'D_I25', 'D_786', 'D_401', 'D_789'])],\n",
    "#  'B1234-C456': [([datetime.datetime(2018, 1, 3, 0, 0)],\n",
    "#    ['D_M05', 'D_Z13', 'D_O99']),\n",
    "#   ([datetime.datetime(2018, 2, 3, 0, 0)],\n",
    "#    ['D_M05', 'D_Z13', 'D_O99', 'D_D37'])]}\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "specialized-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting patient IDs, visit dates and diagnosis codes into individual lists for encoding\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting patient IDs, visit dates and diagnosis codes into individual lists for encoding\")\n",
    "patIDs = [patid for patid, visitDate in patDxVisitOrderMap.items()]\n",
    "datesList = [[visit[0][0] for visit in visitDate] for patid, visitDate in patDxVisitOrderMap.items()]\n",
    "DxsCodesList = [[visit[1] for visit in visitDate] for patid, visitDate in patDxVisitOrderMap.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adult-graham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1234-B456', 'B1234-C456']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patIDs\n",
    "\n",
    "# ```\n",
    "# ['A1234-B456', 'B1234-C456']\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "catholic-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.datetime(2019, 1, 3, 9, 34, 55),\n",
       "  datetime.datetime(2019, 2, 3, 10, 50, 55),\n",
       "  datetime.datetime(2019, 4, 3, 12, 34, 55)],\n",
       " [datetime.datetime(2018, 1, 3, 9, 34, 55),\n",
       "  datetime.datetime(2018, 2, 3, 10, 50, 55)]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datesList\n",
    "\n",
    "# ```\n",
    "# [[datetime.datetime(2019, 1, 3, 0, 0),\n",
    "#   datetime.datetime(2019, 2, 3, 0, 0),\n",
    "#   datetime.datetime(2019, 4, 3, 0, 0)],\n",
    "#  [datetime.datetime(2018, 1, 3, 0, 0), datetime.datetime(2018, 2, 3, 0, 0)]]\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "crucial-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['D_E11', 'D_I25', 'D_I25'],\n",
       "  ['D_E11', 'D_I25', 'D_I25', 'D_780', 'D_784'],\n",
       "  ['D_E11', 'D_I25', 'D_I25', 'D_786', 'D_401', 'D_789']],\n",
       " [['D_M05', 'D_Z13', 'D_O99'], ['D_M05', 'D_Z13', 'D_O99', 'D_D37']]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DxsCodesList\n",
    "\n",
    "# ```\n",
    "# [[['D_E11', 'D_I25', 'D_I25'],\n",
    "#   ['D_E11', 'D_I25', 'D_I25', 'D_780', 'D_784'],\n",
    "#   ['D_E11', 'D_I25', 'D_I25', 'D_786', 'D_401', 'D_789']],\n",
    "#  [['D_M05', 'D_Z13', 'D_O99'], ['D_M05', 'D_Z13', 'D_O99', 'D_D37']]]\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "hydraulic-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "('Encoding string Dx codes to integers and mapping the encoded integer value to the ICD-10 code for interpretation')\n",
    "DxCodeDictionary = {}\n",
    "encodedDxs = []\n",
    "for patient in DxsCodesList:\n",
    "    encodedPatientDxs = []\n",
    "    for visit in patient:\n",
    "        encodedVisit = []\n",
    "        for code in visit:\n",
    "            if code in DxCodeDictionary:\n",
    "                encodedVisit.append(DxCodeDictionary[code])\n",
    "            else:\n",
    "                DxCodeDictionary[code] = len(DxCodeDictionary)\n",
    "                encodedVisit.append(DxCodeDictionary[code])\n",
    "        encodedPatientDxs.append(encodedVisit)\n",
    "    encodedDxs.append(encodedPatientDxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "portuguese-scoop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D_E11': 0,\n",
       " 'D_I25': 1,\n",
       " 'D_780': 2,\n",
       " 'D_784': 3,\n",
       " 'D_786': 4,\n",
       " 'D_401': 5,\n",
       " 'D_789': 6,\n",
       " 'D_M05': 7,\n",
       " 'D_Z13': 8,\n",
       " 'D_O99': 9,\n",
       " 'D_D37': 10}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DxCodeDictionary # Dictionary of all unique codes in the entire dataset aka: Our Code Vocabulary\n",
    "\n",
    "# ```\n",
    "# {'D_E11': 0,\n",
    "#  'D_I25': 1,\n",
    "#  'D_780': 2,\n",
    "#  'D_784': 3,\n",
    "#  'D_786': 4,\n",
    "#  'D_401': 5,\n",
    "#  'D_789': 6,\n",
    "#  'D_M05': 7,\n",
    "#  'D_Z13': 8,\n",
    "#  'D_O99': 9,\n",
    "#  'D_D37': 10}\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "improved-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1, 1], [0, 1, 1, 2, 3], [0, 1, 1, 4, 5, 6]], [[7, 8, 9], [7, 8, 9, 10]]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedDxs # Converted list of list with integer converted diagnosis codes\n",
    "\n",
    "# ```\n",
    "# [[[0, 1, 1], [0, 1, 1, 2, 3], [0, 1, 1, 4, 5, 6]], [[7, 8, 9], [7, 8, 9, 10]]]\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "absolute-botswana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping files into a pickled list\n"
     ]
    }
   ],
   "source": [
    "outFile = 'ArtificialEHR_Data'\n",
    "print('Dumping files into a pickled list')\n",
    "pickle.dump(patIDs, open(outFile+'.patIDs', 'wb'),-1)\n",
    "pickle.dump(datesList, open(outFile+'.dates', 'wb'),-1)\n",
    "pickle.dump(encodedDxs, open(outFile+'.encodedDxs', 'wb'),-1)\n",
    "pickle.dump(DxCodeDictionary, open(outFile+'.Dxdictionary', 'wb'),-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-single",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "choice-cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "import sys, random\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# check if GPU is available\n",
    "if(torch.cuda.is_available()):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('Training on CPU!')\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "hungarian-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(sequences, labels):\n",
    "    dataSize = len(labels)\n",
    "    idx = np.random.permutation(dataSize)\n",
    "    nTest = int(np.ceil(0.15 * dataSize))\n",
    "    nValid = int(np.ceil(0.10 * dataSize))\n",
    "\n",
    "    test_idx = idx[:nTest]\n",
    "    valid_idx = idx[nTest:nTest+nValid]\n",
    "    train_idx = idx[nTest+nValid:]\n",
    "\n",
    "    train_x = sequences[train_idx]\n",
    "    train_y = labels[train_idx]\n",
    "    test_x = sequences[test_idx]\n",
    "    test_y = labels[test_idx]\n",
    "    valid_x = sequences[valid_idx]\n",
    "    valid_y = labels[valid_idx]\n",
    "\n",
    "    train_x = [sorted(seq) for seq in train_x]\n",
    "    train_y = [sorted(seq) for seq in train_y]\n",
    "    valid_x = [sorted(seq) for seq in valid_x]\n",
    "    valid_y = [sorted(seq) for seq in valid_y]\n",
    "    test_x = [sorted(seq) for seq in test_x]\n",
    "    test_y = [sorted(seq) for seq in test_y]\n",
    "\n",
    "    train = (train_x, train_y)\n",
    "    test = (test_x, test_y)\n",
    "    valid = (valid_x, valid_y)\n",
    "    return (train, test, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "official-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(seqs, labels, vocab, n_classes):\n",
    "    lengths = np.array([len(seq) for seq in seqs]) - 1 # remove the last list in each patient's sequences for labels\n",
    "    n_samples = len(lengths)\n",
    "    maxlen = np.max(lengths)\n",
    "\n",
    "    x = torch.zeros(maxlen, n_samples, vocab) # maxlen = number of visits, n_samples = samples\n",
    "    y = torch.zeros(maxlen, n_samples, n_classes)\n",
    "    mask = torch.zeros(maxlen, n_samples)\n",
    "    for idx, (seq,label) in enumerate(zip(seqs,labels)):\n",
    "        for xvec, subseq in zip(x[:,idx,:], seq[:-1]):\n",
    "            xvec[subseq] = 1.\n",
    "        for yvec, subseq in zip(y[:,idx,:], label[1:]):\n",
    "            yvec[subseq] = 1.\n",
    "        mask[:lengths[idx], idx] = 1.\n",
    "        \n",
    "    return x, y, lengths, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "express-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset generator:\n",
    "class Dataset():\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i ): return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "secure-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Sampler class:\n",
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = (len(ds)//bs)*bs,bs,shuffle  \n",
    "        # Note: self.n = (len(ds)//bs) keeps the exact amount of samples needed for your desired batchSize\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "proprietary-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DataLoader:\n",
    "def collate(batch_pairs):\n",
    "    x,y = zip(*batch_pairs)\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ordinary-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
    "    def __len__(self): return len(self.ds)\n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "massive-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embedding Layer:\n",
    "class Custom_Embedding(nn.Module):\n",
    "    def __init__ (self, inputDimSize, embSize):\n",
    "        super(Custom_Embedding, self).__init__()\n",
    "        self.inputDimSize = inputDimSize\n",
    "        self.embSize = embSize\n",
    "        \n",
    "        self.W_emb = nn.Parameter(torch.randn(self.inputDimSize, self.embSize) * 0.01)\n",
    "        self.b_emb = nn.Parameter(torch.zeros(self.embSize) * 0.01) \n",
    "       \n",
    "    def forward(self, x):\n",
    "        return torch.tanh(x@self.W_emb + self.b_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "amateur-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop out Layer:\n",
    "def dropout_mask(x, sz, p):\n",
    "    return x.new(*sz).bernoulli_(1-p).div_(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "analyzed-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRU Cell:\n",
    "class EHR_GRU(Custom_Embedding):\n",
    "    def __init__(self, inputDimSize, hiddenDimSize, embSize, numClass, numLayers):\n",
    "        super().__init__(inputDimSize, embSize)\n",
    "        \n",
    "        self.numClass = numClass\n",
    "        self.numLayers = numLayers\n",
    "        self.hiddenDimSize = hiddenDimSize\n",
    "        self.emb = Custom_Embedding(inputDimSize, embSize)\n",
    "        \n",
    "        self.W_r = nn.Parameter(torch.randn(embSize, hiddenDimSize)* 0.01)\n",
    "        self.W_z = nn.Parameter(torch.randn(embSize, hiddenDimSize)* 0.01)\n",
    "        self.W_h = nn.Parameter(torch.randn(embSize, hiddenDimSize)* 0.01)\n",
    "        \n",
    "        self.U_r = nn.Parameter(torch.randn(hiddenDimSize, hiddenDimSize)* 0.01)\n",
    "        self.U_z = nn.Parameter(torch.randn(hiddenDimSize, hiddenDimSize)* 0.01)\n",
    "        self.U_h = nn.Parameter(torch.randn(hiddenDimSize, hiddenDimSize)* 0.01)\n",
    "        \n",
    "        self.b_r = nn.Parameter(torch.randn(hiddenDimSize))\n",
    "        self.b_z = nn.Parameter(torch.randn(hiddenDimSize))\n",
    "        self.b_h = nn.Parameter(torch.randn(hiddenDimSize))\n",
    "        \n",
    "        self.W_output = nn.Parameter(torch.randn(embSize, numClass))\n",
    "        self.b_output = nn.Parameter(torch.randn(numClass))\n",
    "        \n",
    "    def forward(self, emb, mask):\n",
    "        h = self.init_hidden(emb.size(1))\n",
    "        \n",
    "        z = torch.sigmoid(emb@self.W_z + h@self.U_z + self.b_z) \n",
    "        r = torch.sigmoid(emb@self.W_r + h@self.U_r + self.b_r)\n",
    "        h_tilde = torch.tanh(emb@self.W_h + (r * h)@self.U_h + self.b_h)\n",
    "        h_new = z * h + ((1. - z) * h_tilde)\n",
    "        h_new = mask[:, :, None] * h_new + (1. - mask)[:, :, None] * h\n",
    "       \n",
    "        return h_new\n",
    "    \n",
    "    def init_hidden(self, batchSize):\n",
    "        return Variable(torch.zeros(1, batchSize, hiddenDimSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "floating-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRU Layer:\n",
    "class build_EHR_GRU(EHR_GRU):\n",
    "    def __init__(self, GRUCell, *kwargs):\n",
    "        super().__init__(inputDimSize, hiddenDimSize, embSize, numClass, numLayers)\n",
    "        self.cell = GRUCell(*kwargs)\n",
    "        self.emb = Custom_Embedding(inputDimSize, embSize)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        inputVector = self.emb(x)\n",
    "        for i in range(numLayers):\n",
    "            memories = self.cell(inputVector, mask)\n",
    "            drop_out = dropout_mask(inputVector, (inputVector.size(0), 1, inputVector.size(2)), 0.5)\n",
    "            inputVector = memories * drop_out\n",
    "        \n",
    "        y_linear = inputVector@self.W_output + self.b_output\n",
    "        output = F.softmax(y_linear, dim=1)\n",
    "        output = output * mask[:,:,None]\n",
    "        return output, inputVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "empty-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss Function:\n",
    "class cost_function():\n",
    "    def __init__(self, yhat, y, L_2=0.001, logEps=1e-8):\n",
    "        self.yhat = yhat\n",
    "        self.y = y\n",
    "       \n",
    "        self.logEps = logEps\n",
    "        self.L_2 = L_2\n",
    "        \n",
    "        self.W_out = nn.Parameter(torch.randn(hiddenDimSize, numClass)*0.01)\n",
    "        \n",
    "    def cross_entropy(self):\n",
    "        return  -(self.y * torch.log(self.yhat + self.logEps) + (1. - self.y) * torch.log(1. - self.yhat + self.logEps))\n",
    "    \n",
    "    def prediction_loss(self):\n",
    "        return  (torch.sum(torch.sum(self.cross_entropy(), dim=0),dim=1)).float()/  lengths.float()\n",
    "    \n",
    "    def cost(self):\n",
    "        return torch.mean(self.prediction_loss()) + self.L_2 * (self.W_out ** 2).sum() # regularize\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "activated-singapore",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d5501efad886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Training Loop:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "### Training Loop:\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr = 0.01, rho=0.95)\n",
    "epochs = 10\n",
    "\n",
    "counter = 0\n",
    "for e in range(epochs):\n",
    "    for x, y in train_dl:\n",
    "        x, y , mask, lengths = padding(x, y, inputDimSize, numClass)\n",
    "        \n",
    "        output, h = model(x, mask)\n",
    "        \n",
    "        loss = cost_function(output, y).cost()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_loss = []\n",
    "            for x_valid, y_valid in valid_dl:\n",
    "                    x_val, y_val, mask, lengths = padding(x_valid, y_valid, inputDimSize, numClass)\n",
    "                    outputs_val, hidden_val = model(x_val,  mask)\n",
    "                    loss = cost_function(outputs_val, y_val).cost()\n",
    "                    val_loss.append(loss.item())\n",
    "            model.train()\n",
    "\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                                  \"Step: {}...\".format(counter),\n",
    "                                  \"Training Loss: {:.4f}...\".format(loss.item()),\n",
    "                                  \"Val Loss: {:.4f}\".format(torch.mean(torch.tensor(val_loss))))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-packet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobius (venv)",
   "language": "python",
   "name": "mobius"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
