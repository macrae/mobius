{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funded-chemistry",
   "metadata": {},
   "source": [
    "## Siamese Neural Networks \n",
    "### for Supervised Clustering of High Dimensional Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exact-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.10\n",
      "/Users/seanmacrae/mobius/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polar-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from palmerpenguins import load_penguins\n",
    "# penguins = load_penguins()\n",
    "\n",
    "# print(penguins.shape)\n",
    "# penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bigger-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (19,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887379, 74)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430    1314167     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175    1313524     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863    1277178    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358    1311748     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade  ... total_bal_il il_util  \\\n",
       "0     10.65       162.87     B        B2  ...          NaN     NaN   \n",
       "1     15.27        59.83     C        C4  ...          NaN     NaN   \n",
       "2     15.96        84.33     C        C5  ...          NaN     NaN   \n",
       "3     13.49       339.31     C        C1  ...          NaN     NaN   \n",
       "4     12.69        67.79     B        B5  ...          NaN     NaN   \n",
       "\n",
       "  open_rv_12m  open_rv_24m max_bal_bc all_util total_rev_hi_lim inq_fi  \\\n",
       "0         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "1         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "2         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "3         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "4         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "\n",
       "  total_cu_tl inq_last_12m  \n",
       "0         NaN          NaN  \n",
       "1         NaN          NaN  \n",
       "2         NaN          NaN  \n",
       "3         NaN          NaN  \n",
       "4         NaN          NaN  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DOWNLOAD DATSET HERE: https://www.kaggle.com/husainsb/lendingclub-issued-loans\n",
    "loans = pd.read_csv(\"../data/lc_loan.csv\")\n",
    "\n",
    "print(loans.shape)\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indirect-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loans[\"default\"] = loans[\"loan_status\"] == \"Default\"\n",
    "loans[\"issue_year\"] = [int(x[1]) for x in loans[\"issue_d\"].str.split(\"-\")]\n",
    "\n",
    "loans = loans[loans[\"issue_year\"] == 2015]\n",
    "loans.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inclusive-teacher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421094, 75)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "voluntary-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(loans, hue='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "remarkable-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loans_sample, _ = train_test_split(\n",
    "    loans,\n",
    "    test_size=0.97,\n",
    "    stratify=loans[\"loan_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "boolean-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12632, 75)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-circus",
   "metadata": {},
   "source": [
    "## Tabular Learner\n",
    "\n",
    "Before we train the Tabular Siamese Learner we will train baseline Tabular Learner for species classification... (why do we do this, exactly? can we just instantiate a Tabular Siamese Learner without a baseline Tabular Learner ???)\n",
    "\n",
    "Ah yes, to init a new `TabularSiameseModel` we need to provide an `encoder` and `head` and the Tabular Learner will act as the `encoder` we init the `TabularSiameseModel` with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dangerous-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.model_selection import train_test_split\n",
    "\n",
    "# penguins_train, penguins_test = train_test_split(\n",
    "#     penguins,\n",
    "#     test_size=0.10,\n",
    "#     stratify=penguins[\"species\"])\n",
    "\n",
    "# penguins_train.shape, penguins_test.shape\n",
    "\n",
    "# df = penguins_train.copy()\n",
    "\n",
    "# exclude_vars = [\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "geological-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loans_train, loans_test = train_test_split(\n",
    "    loans_sample,\n",
    "    test_size=0.10,\n",
    "    stratify=loans_sample[\"loan_status\"])\n",
    "\n",
    "loans_train.shape, loans_test.shape\n",
    "\n",
    "df = loans_train.copy()\n",
    "\n",
    "exclude_vars = [\"id\", \"member_id\", \"loan_status\", \"url\", \"last_pymnt_d\", \"next_pymnt_d\", \"policy_code\", \"issue_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "still-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import CategoryBlock\n",
    "                                \n",
    "# y_names = [\"species\"]\n",
    "y_names = [\"loan_status\"]\n",
    "y_block = CategoryBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "human-bracelet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'term': 2,\n",
       " 'grade': 5,\n",
       " 'sub_grade': 12,\n",
       " 'emp_title': 212,\n",
       " 'emp_length': 6,\n",
       " 'home_ownership': 3,\n",
       " 'verification_status': 3,\n",
       " 'issue_d': 6,\n",
       " 'pymnt_plan': 2,\n",
       " 'desc': 3,\n",
       " 'purpose': 7,\n",
       " 'title': 7,\n",
       " 'zip_code': 68,\n",
       " 'addr_state': 14,\n",
       " 'earliest_cr_line': 53,\n",
       " 'initial_list_status': 2,\n",
       " 'last_credit_pull_d': 7,\n",
       " 'application_type': 2,\n",
       " 'verification_status_joint': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mobius.utils import emb_sz_rule\n",
    "\n",
    "cat_names = [x for x in df.select_dtypes(exclude=['int', 'float']).columns if x != y_names]\n",
    "cat_names = [x for x in cat_names if x not in exclude_vars]\n",
    "\n",
    "# calc embedding sizes for each categorical feature\n",
    "emb_szs = {k: emb_sz_rule(len(df[k].unique())) for k in cat_names}\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "greater-channels",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'annual_inc',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'inq_last_6mths',\n",
       " 'mths_since_last_delinq',\n",
       " 'mths_since_last_record',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'out_prncp',\n",
       " 'out_prncp_inv',\n",
       " 'total_pymnt',\n",
       " 'total_pymnt_inv',\n",
       " 'total_rec_prncp',\n",
       " 'total_rec_int',\n",
       " 'total_rec_late_fee',\n",
       " 'recoveries',\n",
       " 'collection_recovery_fee',\n",
       " 'last_pymnt_amnt',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'mths_since_last_major_derog',\n",
       " 'annual_inc_joint',\n",
       " 'dti_joint',\n",
       " 'acc_now_delinq',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'open_acc_6m',\n",
       " 'open_il_6m',\n",
       " 'open_il_12m',\n",
       " 'open_il_24m',\n",
       " 'mths_since_rcnt_il',\n",
       " 'total_bal_il',\n",
       " 'il_util',\n",
       " 'open_rv_12m',\n",
       " 'open_rv_24m',\n",
       " 'max_bal_bc',\n",
       " 'all_util',\n",
       " 'total_rev_hi_lim',\n",
       " 'inq_fi',\n",
       " 'total_cu_tl',\n",
       " 'inq_last_12m']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cont_names = [x for x in df.select_dtypes([np.number]).columns if x != y_names]\n",
    "cont_names = [x for x in cont_names if x not in exclude_vars]\n",
    "cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "everyday-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import (Categorify, CategoryBlock, FillMissing,\n",
    "                                Normalize, TabDataLoader, TabularPandas,\n",
    "                                tabular_config, tabular_learner)\n",
    "\n",
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "heated-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import range_of\n",
    "from fastai.tabular.all import RandomSplitter\n",
    "\n",
    "# # train/test split\n",
    "splits = RandomSplitter(valid_pct=0.10)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "italic-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_pandas = TabularPandas(\n",
    "        df,\n",
    "        procs=procs,\n",
    "        cat_names=cat_names,\n",
    "        cont_names=cont_names,\n",
    "        y_names=y_names,\n",
    "        y_block=y_block,\n",
    "        splits=splits,\n",
    "        device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "backed-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = TabDataLoader(\n",
    "    tabular_pandas.train,\n",
    "    bs=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,)\n",
    "#     num_workers=1)\n",
    "\n",
    "val_dl = TabDataLoader(\n",
    "    tabular_pandas.valid,\n",
    "    bs=128,)\n",
    "#     num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "above-brisbane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  8,  ...,  2,  2,  2],\n",
       "         [ 1,  3, 12,  ...,  2,  2,  2],\n",
       "         [ 1,  1,  5,  ...,  2,  2,  2],\n",
       "         ...,\n",
       "         [ 1,  1,  1,  ...,  2,  2,  2],\n",
       "         [ 2,  3, 14,  ...,  2,  2,  2],\n",
       "         [ 1,  1,  3,  ...,  2,  2,  2]]),\n",
       " tensor([[-0.9668, -0.9668, -0.9665,  ..., -0.1270, -0.1117, -0.0718],\n",
       "         [-0.6188, -0.6188, -0.6242,  ..., -0.1270, -0.1117, -0.0718],\n",
       "         [-1.0828, -1.0828, -1.0825,  ..., -0.1270, -0.1117, -0.0718],\n",
       "         ...,\n",
       "         [-0.7348, -0.7348, -0.7344,  ..., -0.1270, -0.1117, -0.0718],\n",
       "         [-0.3868, -0.3868, -0.3863,  ..., -0.1270, -0.1117, -0.0718],\n",
       "         [-0.8508, -0.8508, -0.8504,  ..., -0.1270, -0.1117, -0.0718]]),\n",
       " tensor([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [7],\n",
       "         [1],\n",
       "         [7],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [7],\n",
       "         [3],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [3],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [5],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [7],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [4],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [5],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]], dtype=torch.int8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)\n",
    "\n",
    "print(\"Sample batch:\")\n",
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "direct-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import F1Score, Precision, Recall, accuracy\n",
    "\n",
    "# load the tabular_pandas data through the tabular_learner\n",
    "layers = [2048, 1024, 32, 2]\n",
    "\n",
    "# tabular learner configuration\n",
    "config = tabular_config(ps=[0.2, 0.1, 0.1, 0.0], embed_p=0.1)\n",
    "\n",
    "# import ipdb; ipdb.set_trace()\n",
    "learn = tabular_learner(\n",
    "    dls,\n",
    "    layers=layers,\n",
    "    emb_szs=emb_szs,\n",
    "    # loss_func=f1_loss_func,\n",
    "    config=config,\n",
    "    metrics=[accuracy,\n",
    "             Precision(average='macro'),\n",
    "             Recall(average='macro'),\n",
    "             F1Score(average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "loving-research",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.533820</td>\n",
       "      <td>2.530330</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.151786</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.445053</td>\n",
       "      <td>2.340379</td>\n",
       "      <td>0.049296</td>\n",
       "      <td>0.119828</td>\n",
       "      <td>0.231173</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.821485</td>\n",
       "      <td>1.123364</td>\n",
       "      <td>0.692782</td>\n",
       "      <td>0.244355</td>\n",
       "      <td>0.189499</td>\n",
       "      <td>0.201871</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.953100</td>\n",
       "      <td>0.611989</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.278253</td>\n",
       "      <td>0.218247</td>\n",
       "      <td>0.243321</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.622652</td>\n",
       "      <td>0.516502</td>\n",
       "      <td>0.845951</td>\n",
       "      <td>0.272051</td>\n",
       "      <td>0.247139</td>\n",
       "      <td>0.258956</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>0.472592</td>\n",
       "      <td>0.855634</td>\n",
       "      <td>0.274178</td>\n",
       "      <td>0.244280</td>\n",
       "      <td>0.258122</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.368843</td>\n",
       "      <td>0.469667</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.345982</td>\n",
       "      <td>0.255129</td>\n",
       "      <td>0.275320</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.336376</td>\n",
       "      <td>0.463960</td>\n",
       "      <td>0.852113</td>\n",
       "      <td>0.269117</td>\n",
       "      <td>0.243718</td>\n",
       "      <td>0.255687</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.316994</td>\n",
       "      <td>0.465880</td>\n",
       "      <td>0.852113</td>\n",
       "      <td>0.321947</td>\n",
       "      <td>0.250305</td>\n",
       "      <td>0.271537</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.319440</td>\n",
       "      <td>0.469549</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.343098</td>\n",
       "      <td>0.252928</td>\n",
       "      <td>0.272802</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(n_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "frequent-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"tabular_learn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "artificial-mileage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before temperature - NLL: 0.470, ECE: 0.044\n",
      "Optimal temperature: 0.912\n",
      "After temperature - NLL: 0.484, ECE: 0.047\n"
     ]
    }
   ],
   "source": [
    "from mobius.calibration import ModelWithTemperature\n",
    "\n",
    "scaled_model = ModelWithTemperature(learn.model)\n",
    "scaled_model.set_temperature(val_dl)\n",
    "learn.model = scaled_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expressed-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanmacrae/mobius/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# true species labels\n",
    "y_true=learn.dls.valid.items[\"loan_status\"]\n",
    "\n",
    "# model scores and species predictions\n",
    "y_scores, *_ = learn.get_preds(dl=val_dl)\n",
    "preds = np.argmax(y_scores, 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "proper-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 species labels and predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 4),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 4)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First 20 species labels and predictions\")\n",
    "list(zip(y_true, preds))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "appropriate-tuner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547535211267606"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_true == preds).sum() / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "considered-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update roc-it with MultiClassClassification...\n",
    "\n",
    "# clf_metrics = BinaryClassification(\n",
    "#     y_true=y_true, y_scores=y_scores)\n",
    "\n",
    "# ths = clf_metrics.recall_curve(0.95)\n",
    "\n",
    "# clf_metrics.plot_confusion_matrix(\n",
    "#     ths=0.50,\n",
    "#     normalize=None,\n",
    "#     save_path=f'{hyperparams[\"artifact_dir\"]}/cm.png')\n",
    "\n",
    "# clf_metrics.plot_pr_curve(\n",
    "#     save_path=f'{hyperparams[\"artifact_dir\"]}/pr_curve.png')\n",
    "\n",
    "# clf_metrics.plot_roc_curve(\n",
    "#     save_path=f'{hyperparams[\"artifact_dir\"]}/roc_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-drilling",
   "metadata": {},
   "source": [
    "## Siamese Net\n",
    "\n",
    "To init a new `TabularSiameseDataset` object, we only need a `tabular_pandas` object from the fast.ai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adolescent-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.datasets import TabularSiameseDataset\n",
    "\n",
    "# sds = TabularSiameseDataset(tabular_pandas)\n",
    "train_ds = TabularSiameseDataset(tabular_pandas.train)\n",
    "valid_ds = TabularSiameseDataset(tabular_pandas.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "republican-audit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([   2,    3,   12, 3169,    2,    2,    1,    3,    1,    0,    3,    4,\n",
       "           619,   42,  492,    2,    7,    1,    0,    2,    2,    1,    2,    2,\n",
       "             2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1]),\n",
       "  tensor([-3.8790e-02, -3.8790e-02, -3.8131e-02,  6.0707e-02, -4.2194e-01,\n",
       "          -6.6038e-01,  1.2029e+00, -3.7138e-01, -6.6686e-01, -9.7150e-02,\n",
       "           9.7295e-03, -1.2477e+00, -3.7464e-01, -8.4034e-02,  2.7299e-01,\n",
       "          -1.6335e+00,  2.4945e-01,  2.5015e-01, -7.4749e-01, -7.4754e-01,\n",
       "          -5.9568e-01, -9.2352e-01, -5.1084e-02, -1.6687e-02, -2.3601e-02,\n",
       "          -3.1684e-01, -1.2644e-01, -1.8103e-03, -1.4228e-02, -4.6833e-03,\n",
       "          -7.5840e-02, -1.4422e-01, -6.3909e-01,  1.5656e-03, -6.0226e-02,\n",
       "           3.6323e+00,  2.5408e+00, -1.4292e+00,  2.1500e-01,  3.0205e+00,\n",
       "          -3.2988e+00, -3.5835e+00,  3.5367e+00,  3.3780e+00, -2.2053e-01,\n",
       "          -1.2702e-01, -1.1174e-01, -1.4600e+00])),\n",
       " (tensor([   2,    7,   32, 4952,    2,    2,    3,    9,    1,    0,    3,    4,\n",
       "            78,   33,  201,    2,    7,    1,    0,    1,    2,    1,    2,    2,\n",
       "             2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "             2,    2,    2]),\n",
       "  tensor([ 4.5314e-02,  4.5314e-02,  4.6001e-02,  3.4191e+00,  1.5942e-01,\n",
       "           3.3292e-01, -5.4362e-01, -3.7138e-01,  1.6691e+00, -9.7150e-02,\n",
       "           9.7295e-03,  1.0802e+00, -3.7464e-01, -6.1413e-02,  1.3013e-01,\n",
       "           1.4021e+00,  2.0667e-01,  2.0735e-01,  1.5523e-01,  1.5553e-01,\n",
       "          -3.1942e-01,  2.1218e+00, -5.1084e-02, -1.6687e-02, -2.3601e-02,\n",
       "          -1.8183e-01, -1.2644e-01, -1.8103e-03, -1.4228e-02, -4.6833e-03,\n",
       "          -7.5840e-02, -1.4422e-01, -5.9476e-01,  1.5656e-03, -6.0226e-02,\n",
       "          -1.3551e-01, -8.0178e-02, -6.9135e-02, -6.8011e-02,  3.0352e-02,\n",
       "          -4.2957e-02, -7.2236e-02, -6.2639e-02,  2.1430e-03, -1.4682e-01,\n",
       "          -1.2702e-01, -1.1174e-01, -7.1770e-02])),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sensitive-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=32, device='cpu', num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-republic",
   "metadata": {},
   "source": [
    "Siamese net encoder is the body of the Tabular net we just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "limited-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "encoder = copy.copy(learn)\n",
    "encoder.model.layers = learn.model.layers[:-1]\n",
    "encoder_model = encoder.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-birthday",
   "metadata": {},
   "source": [
    "We create a new head that doubles the input shape to the last layer of the trained Tabular net, since the loss function will now compare 2 penguins. The size of the output shape is set by...???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "municipal-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.layers import LinBnDrop\n",
    "\n",
    "head = LinBnDrop(n_in=layers[-1]*2,\n",
    "    n_out=16,  # size of output space\n",
    "    bn=True,\n",
    "    act=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abroad-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.models import TabularSiameseModel\n",
    "\n",
    "model = TabularSiameseModel(encoder_model, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "turkish-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_basics import params\n",
    "from mobius.losses import ContrastiveLoss\n",
    "\n",
    "def siamese_splitter(model):\n",
    "    return [params(model.encoder), params(model.head)]\n",
    "\n",
    "def contrastive_loss_func(out, targ):\n",
    "    return ContrastiveLoss(margin=0.10)(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "indirect-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import Learner\n",
    "\n",
    "siamese_learner = Learner(dls,\n",
    "    model,\n",
    "    model_dir=\".\",\n",
    "    loss_func=contrastive_loss_func,\n",
    "    splitter=siamese_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-fruit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      11.11% [4/36 00:09<01:13 8.2567]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %debug\n",
    "siamese_learner.freeze()\n",
    "siamese_learner.fit_one_cycle(n_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_learner.unfreeze()\n",
    "\n",
    "lr_min, _ = siamese_learner.lr_find()\n",
    "siamese_learner.fit(n_epoch=5, lr=lr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_learner.save(\"snn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train kNN on encoded penguins_train (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_encoded = list()\n",
    "for i in tqdm(range(len(dls.train_ds.tabular_pandas))):\n",
    "    # get ith point from the training set\n",
    "    p, _, _ = dls.train_ds.get_items(i, 0)\n",
    "\n",
    "    # rehsape into mini-batch size 1\n",
    "    p = p[0].reshape(1, -1), p[1].reshape(1, -1)\n",
    "\n",
    "    # encode the household into output embedding space\n",
    "    p_encode = siamese_learner.model.encode(p)\n",
    "    train_encoded.append(p_encode)\n",
    "    \n",
    "ids = dls.train.get_idxs()\n",
    "y_train_labels = dls.train.tabular_pandas[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "train_encoded_df = pd.DataFrame(torch.stack(train_encoded).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_encoded_df[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "sns.scatterplot(x=train_encoded_df[0].values,\n",
    "                y=train_encoded_df[1].values,\n",
    "                hue=y_train_labels, \n",
    "                legend='full', \n",
    "                palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "tsne = TSNE()\n",
    "encoded_train_tsne = tsne.fit_transform(train_encoded_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=encoded_train_tsne[:,0],\n",
    "                y=encoded_train_tsne[:,1],\n",
    "                hue=y_train_labels, \n",
    "                legend='full', \n",
    "                palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(train_encoded_df.values, y_train_labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-progress",
   "metadata": {},
   "source": [
    "We have now fit 3 models to predict penguin species - first, a multi-class Tabular learner was fit on penguins; then, a Siamese net was fit to discern likeness between pairs of penguins; lastly, a kNN supervised clustering algorithm was applied to the output of the Siamese Encoder (the manifold space) to predict species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-scott",
   "metadata": {},
   "source": [
    "## Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "valid_encoded = list()\n",
    "for i in tqdm(range(len(dls.valid_ds.tabular_pandas))):\n",
    "    # get ith point from the training set\n",
    "    p, _, _ = dls.valid_ds.get_items(i, 0)\n",
    "\n",
    "    # rehsape into mini-batch size 1\n",
    "    p = p[0].reshape(1, -1), p[1].reshape(1, -1)\n",
    "\n",
    "    # encode the household into output embedding space\n",
    "    p_encode = siamese_learner.model.encode(p)\n",
    "    valid_encoded.append(p_encode)\n",
    "    \n",
    "valid_ids = dls.valid.get_idxs()\n",
    "y_valid_labels = dls.valid.tabular_pandas[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_encoded_df = pd.DataFrame(torch.stack(valid_encoded).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_valid_tsne = tsne.fit_transform(valid_encoded_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=encoded_valid_tsne[:,0],\n",
    "                y=encoded_valid_tsne[:,1],\n",
    "                hue=y_valid_labels, \n",
    "                legend='full', \n",
    "                palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(zip(knn.predict(valid_encoded_df), y_valid_labels), columns=[\"pred\", \"true\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "(res[\"pred\"] == res[\"true\"]).sum() / len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res[\"true\"] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as multiclass_eval\n",
    "\n",
    "prec, recall, fbeta, _ = multiclass_eval(res[\"true\"].values, res[\"pred\"].values, average=\"macro\")\n",
    "\n",
    "f\"precision {prec}, recall {recall}, fbeta {fbeta}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "embedding = reducer.fit_transform(valid_encoded_df.values)\n",
    "embedding.shape\n",
    "\n",
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=[sns.color_palette()[x] for x in y_valid_labels.values])\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of the LC Loans', fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-church",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobius (venv)",
   "language": "python",
   "name": "mobius"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
