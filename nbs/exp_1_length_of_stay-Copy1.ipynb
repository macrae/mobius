{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confidential-dominant",
   "metadata": {},
   "source": [
    "## Siamese Neural Networks \n",
    "### for Supervised Clustering of High Dimensional Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from loaderbot.big_query import query_table_and_cache\n",
    "from google.cloud import bigquery\n",
    "\n",
    "sql = \"\"\"WITH matches AS (\n",
    "    SELECT DISTINCT\n",
    "        account_id,\n",
    "        windfall_id ,\n",
    "        candidate_id,\n",
    "        confidence,\n",
    "        CASE \n",
    "         -- luxury\n",
    "         WHEN account_id = 81 THEN \"1stDibs\"\n",
    "         WHEN account_id = 614 THEN \"TamaraMellon\"\n",
    "         WHEN account_id = 585 THEN \"Tonal\"\n",
    "         -- WHEN account_id = 385 THEN \"WheelsUp\"\n",
    "         -- WHEN account_id = 208 THEN \"Inspirato\"\n",
    "         -- WHEN account_id = 1577 THEN \"OneFlight\"\n",
    "         -- alternative investment\n",
    "         -- WHEN account_id = 501 THEN \"Cadre\"\n",
    "         -- WHEN account_id = 679 THEN \"Crowdstreet\"\n",
    "         -- WHEN account_id = 1047 THEN \"Equaim\"\n",
    "         -- WHEN account_id = 1218 THEN \"EquityEstates\"\n",
    "         -- WHEN account_id = 1246 THEN \"EquityMultiple\"\n",
    "         WHEN account_id = 1050 THEN \"MasterWorks\"\n",
    "         WHEN account_id = 753 THEN \"Microventures\"\n",
    "         -- WHEN account_id = 1473 THEN \"Portfolia\"        \n",
    "         -- insurance\n",
    "         -- WHEN account_id = 514 THEN \"HealthIQ\"\n",
    "         -- WHEN account_id = 1344 THEN \"PureInsurance\"\n",
    "         -- finance\n",
    "         -- WHEN account_id = 1219 THEN \"SmartBiz\"\n",
    "         -- health\n",
    "         -- WHEN account_id = 220 THEN \"GrandViewHealth\"\n",
    "         -- WHEN account_id = 352 THEN \"NewEnglandBaptistHospital\"\n",
    "         -- WHEN account_id = 1216 THEN \"NuvanceHealth\"\n",
    "         -- WHEN account_id = 654 THEN \"ProvidenceHealth\"\n",
    "         -- WHEN account_id = 1197 THEN \"StCharles\"\n",
    "         END AS account_name,\n",
    "         CASE \n",
    "         -- luxury\n",
    "         WHEN account_id = 81 THEN \"lux\"\n",
    "         WHEN account_id = 614 THEN \"lux\"\n",
    "         WHEN account_id = 585 THEN \"lux\"\n",
    "         -- WHEN account_id = 385 THEN \"lux\"\n",
    "         -- WHEN account_id = 208 THEN \"lux\"\n",
    "         -- WHEN account_id = 1577 THEN \"lux\"\n",
    "         -- alternative investment\n",
    "         -- WHEN account_id = 501 THEN \"alt\"\n",
    "         -- WHEN account_id = 679 THEN \"alt\"\n",
    "         -- WHEN account_id = 1047 THEN \"alt\"\n",
    "         -- WHEN account_id = 1218 THEN \"alt\"\n",
    "         -- WHEN account_id = 1246 THEN \"alt\"\n",
    "         WHEN account_id = 1050 THEN \"alt\"\n",
    "         WHEN account_id = 753 THEN \"alt\"\n",
    "         -- WHEN account_id = 1473 THEN \"alt\"\n",
    "         -- insurance\n",
    "         -- WHEN account_id = 514 THEN \"insurance\"\n",
    "         -- WHEN account_id = 1344 THEN \"insurance\"\n",
    "         -- finance\n",
    "         -- WHEN account_id = 1219 THEN \"finance\"\n",
    "         -- health\n",
    "         -- WHEN account_id = 220 THEN \"health-donor\"\n",
    "         -- WHEN account_id = 352 THEN \"health-donor\"\n",
    "         -- WHEN account_id = 1216 THEN \"health-donor\"\n",
    "         -- WHEN account_id = 654 THEN \"health-donor\"\n",
    "         -- WHEN account_id = 1197 THEN \"health-donor\"\n",
    "         END AS label,\n",
    "    FROM `portal.match`\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    m.label,\n",
    "    audience.*,\n",
    "    latest.city,\n",
    "    latest.state,\n",
    "    latest.zipcode,\n",
    "    latest.county,\n",
    "    latest.metroName,\n",
    "    realEstateInvestor,\n",
    "    personalInvestor,\n",
    "    FROM\n",
    "    `tranquil-garage-139216.people.audience_latest` audience\n",
    "    LEFT JOIN `tranquil-garage-139216.people.audience_dbusa_features` dbusa using(id)\n",
    "    LEFT JOIN `tranquil-garage-139216.people.latest` latest ON latest.id = audience.id\n",
    "    LEFT JOIN matches m ON audience.id = m.windfall_id\n",
    "    WHERE m.label IS NOT NULL\n",
    "    AND m.confidence > 0.90\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "raw_data_name = hashlib.md5(sql.encode('utf-8')).hexdigest()\n",
    "\n",
    "if os.path.exists(f\"data/{raw_data_name}.csv\"):\n",
    "    raw_data = pd.read_csv(f\"data/{raw_data_name}.csv\")\n",
    "else:\n",
    "    raw_data = query_table_and_cache(sql=sql)\n",
    "    raw_data.to_csv(f\"data/{raw_data_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df, _ = train_test_split(\n",
    "    raw_data,\n",
    "    test_size=0.980,\n",
    "    stratify=raw_data[\"label\"])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-requirement",
   "metadata": {},
   "source": [
    "## Tabular Learner\n",
    "\n",
    "Before we train the Tabular Siamese Learner we will train baseline Tabular Learner for species classification... (why do we do this, exactly? can we just instantiate a Tabular Siamese Learner without a baseline Tabular Learner ???)\n",
    "\n",
    "Ah yes, to init a new `TabularSiameseModel` we need to provide an `encoder` and `head` and the Tabular Learner will act as the `encoder` we init the `TabularSiameseModel` with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "    df,\n",
    "    test_size=0.20,\n",
    "    stratify=df[\"label\"])\n",
    "\n",
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import CategoryBlock\n",
    "                                \n",
    "y_names = [\"label\"]\n",
    "y_block = CategoryBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_vars = [\"label\", \"id\", \"investorId\", \"createdAt\", \"investorId_1\", \"investorId_2\",\n",
    "               \"investorLevel\", \"investorLevel_1\", \"status\", \"windfall_id\", \"windfall_id_1\",\n",
    "                \"candidate_id\", \"minInvestmentDate\", \"maxInvestmentDate\", \"confidence\", \n",
    "                \"closed\", \"countInvestmentDate\", \"amount\", \"sumAmount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.utils import emb_sz_rule\n",
    "\n",
    "cat_names = [x for x in df.select_dtypes(exclude=['int', 'float']).columns if x != y_names]\n",
    "cat_names = [x for x in cat_names if x not in exclude_vars]\n",
    "\n",
    "# calc embedding sizes for each categorical feature\n",
    "emb_szs = {k: emb_sz_rule(len(df[k].unique())) for k in cat_names}\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cont_names = [x for x in df.select_dtypes([np.number]).columns if x != y_names]\n",
    "cont_names = [x for x in cont_names if x not in exclude_vars]\n",
    "cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import (Categorify, CategoryBlock, FillMissing, FillStrategy,\n",
    "                                Normalize, TabDataLoader, TabularPandas,\n",
    "                                tabular_config, tabular_learner)\n",
    "# from collections import defaultdict\n",
    "# from dataclasses import dataclass, field\n",
    "\n",
    "# @dataclass\n",
    "# class MyFillMissing(FillMissing):\n",
    "#     fill_strategy:FillStrategy=FillStrategy.constant\n",
    "#     add_col:bool=False\n",
    "#     fill_vals:float=field(default_factory=dict)\n",
    "\n",
    "# procs = [MyFillMissing, Categorify, Normalize]\n",
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import range_of\n",
    "from fastai.tabular.all import RandomSplitter\n",
    "\n",
    "# train/test split\n",
    "splits = RandomSplitter(valid_pct=0.10)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_pandas = TabularPandas(\n",
    "        df,\n",
    "        procs=procs,\n",
    "        cat_names=cat_names,\n",
    "        cont_names=cont_names,\n",
    "        y_names=y_names,\n",
    "        y_block=y_block,\n",
    "        splits=splits,\n",
    "        device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = TabDataLoader(\n",
    "    tabular_pandas.train,\n",
    "    bs=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=4)\n",
    "\n",
    "val_dl = TabDataLoader(\n",
    "    tabular_pandas.valid,\n",
    "    bs=128,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)\n",
    "\n",
    "print(\"Sample batch:\")\n",
    "# dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import F1Score, Precision, Recall, accuracy\n",
    "\n",
    "# load the tabular_pandas data through the tabular_learner\n",
    "layers = [2048, 1024, 128]\n",
    "\n",
    "# tabular learner configuration\n",
    "config = tabular_config(ps=[0.03, 0.03, 0.0], embed_p=0.03)\n",
    "\n",
    "learn = tabular_learner(\n",
    "    dls,\n",
    "    layers=layers,\n",
    "    emb_szs=emb_szs,\n",
    "    config=config,\n",
    "    metrics=[accuracy,\n",
    "             Precision(average='macro'),\n",
    "             Recall(average='macro'),\n",
    "             F1Score(average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.export(\"tabular_learn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mobius.calibration import ModelWithTemperature\n",
    "\n",
    "# scaled_model = ModelWithTemperature(learn.model)\n",
    "# scaled_model.set_temperature(val_dl)\n",
    "# learn.model = scaled_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true species labels\n",
    "y_true=learn.dls.valid.items[\"label\"]\n",
    "\n",
    "# model scores and species predictions\n",
    "y_scores, *_ = learn.get_preds(dl=val_dl)\n",
    "preds = np.argmax(y_scores, 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 20 investor labels and predictions\")\n",
    "list(zip(y_true, preds))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_true == preds).sum() / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-tamil",
   "metadata": {},
   "source": [
    "## Siamese Net\n",
    "\n",
    "To init a new `TabularSiameseDataset` object, we only need a `tabular_pandas` object from the fast.ai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.datasets import write_jsonl\n",
    "\n",
    "# write SNN training data to `data/`\n",
    "write_jsonl(tabular_pandas.train.to.items[0].items, \"data/train_data.jsonl\")\n",
    "write_jsonl(tabular_pandas.valid.to.items[0].items, \"data/valid_data.jsonl\")\n",
    "\n",
    "# write SNN training labels to `data/`\n",
    "tabular_pandas.train.y.to_csv(\"data/train_labels.csv\", index=True)\n",
    "tabular_pandas.valid.y.to_csv(\"data/valid_labels.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.datasets import TabularSiameseDataset\n",
    "\n",
    "train_ds = TabularSiameseDataset(\n",
    "    csv_file=\"data/train_labels.csv\", \n",
    "    jsonl_file=\"data/train_data.jsonl\",\n",
    "    tabular_learner=learn)\n",
    "    \n",
    "valid_ds = TabularSiameseDataset(\n",
    "    csv_file=\"data/valid_labels.csv\", \n",
    "    jsonl_file=\"data/valid_data.jsonl\",\n",
    "    tabular_learner=learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.__len__(), train_ds.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds.__len__(), valid_ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=128, device='cpu', num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-dylan",
   "metadata": {},
   "source": [
    "Siamese net encoder is the body of the Tabular net we just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.dataset.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "encoder = copy.copy(learn)\n",
    "encoder.model.layers = learn.model.layers[:-1]\n",
    "encoder_model = encoder.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.layers import LinBnDrop\n",
    "\n",
    "head = LinBnDrop(n_in=layers[-1]*2,\n",
    "    n_out=16,  # size of output space\n",
    "    bn=True,\n",
    "    act=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobius.models import TabularSiameseModel\n",
    "\n",
    "model = TabularSiameseModel(encoder_model, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_basics import params\n",
    "from mobius.losses import ContrastiveLoss\n",
    "\n",
    "def siamese_splitter(model):\n",
    "    return [params(model.encoder), params(model.head)]\n",
    "\n",
    "def contrastive_loss_func(out, targ):\n",
    "    return ContrastiveLoss(margin=0.50)(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import Learner\n",
    "from mobius.callbacks import TSNECallback\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "\n",
    "# TODO: add callback for best validation\n",
    "siamese_learner = Learner(dls,\n",
    "    model,\n",
    "    model_dir=\".\",\n",
    "    loss_func=contrastive_loss_func,\n",
    "    splitter=siamese_splitter,\n",
    "    cbs=[TSNECallback, SaveModelCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_learner.unfreeze()\n",
    "siamese_learner.fit(n_epoch=5, lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_learner.fit(n_epoch=10, lr=10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_learner.fit(n_epoch=5, lr=10e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_learner.fit(n_epoch=10, lr=10e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-interval",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# siamese_learner.unfreeze()\n",
    "# siamese_learner.fit(n_epoch=3, lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = np.load(\"tsne_1625777058_0.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobius (venv)",
   "language": "python",
   "name": "mobius"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
